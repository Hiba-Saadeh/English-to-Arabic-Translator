{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBpz9dQVkKY6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional,RepeatVector,TimeDistributed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-processing"
      ],
      "metadata": {
        "id": "pu2rse71nSwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r'([!#$%&\\()*+,-./:;<=>?@\\[\\\\\\]^_`{|}~])'\n",
        "text_pairs=[]\n",
        "eng_vocab=[]\n",
        "ara_vocab=[]\n",
        "max_seq_ara=0\n",
        "max_seq_eng=0\n",
        "with open(\"ara_eng.txt\",\"r\", encoding='utf-8') as file:\n",
        "  for line in file:\n",
        "      eng,ara=line.split(\"\\t\")\n",
        "      eng = re.sub(pattern, r' \\1 ', eng)\n",
        "      eng=eng.strip()\n",
        "      eng=eng.lower()\n",
        "\n",
        "      eng_words= eng.split(\" \")\n",
        "      if len(eng_words)>max_seq_eng:\n",
        "        max_seq_eng= len(eng_words)\n",
        "\n",
        "      for word in eng_words:\n",
        "        if word not in eng_vocab:\n",
        "          eng_vocab.append(word)\n",
        "\n",
        "\n",
        "      ara = re.sub(pattern, r' \\1 ', ara)\n",
        "      ara=ara.strip()\n",
        "      ara=\"<start> \"+ara+\" <end>\"\n",
        "      ara_words= ara.split(\" \")\n",
        "      \n",
        "      if len(ara_words)>max_seq_ara:\n",
        "        max_seq_ara= len(ara_words)\n",
        "\n",
        "      for word in ara_words:\n",
        "        if word not in ara_vocab:\n",
        "          if (word != '<start>') and (word != '<end>'):\n",
        "            ara_vocab.append(word)\n",
        "\n",
        "      \n",
        "\n",
        "      text_pairs.append((eng,ara))\n",
        "#text_pairs"
      ],
      "metadata": {
        "id": "73zvswMbHtta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vocab_len= len(eng_vocab)\n",
        "ara_vocab_len= len(ara_vocab)\n",
        "#max_seq_len= max(max_seq_eng, max_seq_ara)\n",
        "max_seq_len=20\n",
        "print(eng_vocab_len)\n",
        "print(ara_vocab_len)\n",
        "print(max_seq_ara)\n",
        "print(max_seq_eng)\n",
        "print(max_seq_len)"
      ],
      "metadata": {
        "id": "PUe5zHjxJz7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99a46bc-5965-4d16-f94d-d2f49381b44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26104\n",
            "57892\n",
            "227\n",
            "226\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data:\n",
        "random.shuffle(text_pairs)\n",
        "test_num= int(0.2 * len(text_pairs))\n",
        "test_data= text_pairs[:test_num]\n",
        "train_data= text_pairs[test_num:]\n",
        "print(len(text_pairs))\n",
        "print(len(test_data))\n",
        "print(len(train_data))\n",
        "print(len(train_data)+len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2Zyxoq0FdfI",
        "outputId": "32082ce7-a136-4147-ce66-aa857d04220e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24638\n",
            "4927\n",
            "19711\n",
            "24638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vector= TextVectorization(max_tokens= eng_vocab_len, output_mode=\"int\", output_sequence_length= max_seq_len)\n",
        "ara_vector= TextVectorization(max_tokens= ara_vocab_len, output_mode=\"int\", output_sequence_length= max_seq_len +1)"
      ],
      "metadata": {
        "id": "LsNKpQRQxmJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train data vectorization \n",
        "\n",
        "train_eng=[t[0] for t in train_data ]\n",
        "train_ara=[t[1] for t in train_data ]\n",
        "eng_vector.adapt(train_eng)\n",
        "ara_vector.adapt(train_ara)"
      ],
      "metadata": {
        "id": "M3TeusF1zbXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(english, arabic):\n",
        "  eng_train= eng_vector(english)\n",
        "  ara_train= ara_vector(arabic)\n",
        "  return ({\"encoder_inputs\": eng_train, \"decoder_inputs\": ara_train[:, :-1],}, ara_train[:, 1:])"
      ],
      "metadata": {
        "id": "z_Nz18FIBO44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset(pairs):\n",
        "  english, arabic= zip(*text_pairs)\n",
        "  english= list(english)\n",
        "  arabic= list(arabic)\n",
        "  dataset= tf.data.Dataset.from_tensor_slices((english,arabic))\n",
        "  dataset= dataset.batch(64)\n",
        "  dataset= dataset.map(format_dataset)\n",
        "  return dataset.shuffle(2048).prefetch(16).cache()"
      ],
      "metadata": {
        "id": "SKKm6VMD_4Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset= dataset(train_data)\n",
        "test_dataset= dataset(test_data)"
      ],
      "metadata": {
        "id": "Tt68B8yk6Hxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "AxXf8Mt02jA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_dataset.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "id": "8WLzYkBv7E-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284adf08-9b76-4ebb-9407-e0f4f145d8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 50)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 50)\n",
            "targets.shape: (64, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "iKjFILXDnVRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "import tensorflow.keras.layers as layers"
      ],
      "metadata": {
        "id": "dtnjyLiYpJCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "KBSSIsPZYWhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n"
      ],
      "metadata": {
        "id": "46OLfy7oYo0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ],
      "metadata": {
        "id": "3d4XLSasYswi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim= 256\n",
        "dense_dim= 2048\n",
        "heads=8\n",
        "\n",
        "#ENCODER:\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(max_seq_len, ara_vocab_len, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "fOzzVqSUJo9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(max_seq_len, ara_vocab_len, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, heads)(x, encoded_seq_inputs)\n",
        "decoder_outputs = layers.Dense(ara_vocab_len, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "metadata": {
        "id": "QKjDpWqmZSxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25 # This should be at least 30 for convergence\n",
        "#opt=adam\n",
        "transformer.summary()\n",
        "transformer.compile(\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "transformer.fit(train_dataset, epochs=epochs, validation_data=test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLj-WIUqa1N2",
        "outputId": "083f1d58-fe55-4d56-aabf-1831c70e8d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Positi  (None, None, 256)   14825472    ['encoder_inputs[0][0]']         \n",
            " onalEmbedding)                                                                                   \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Transfo  (None, None, 256)   3155456     ['positional_embedding_2[0][0]'] \n",
            " rmerEncoder)                                                                                     \n",
            "                                                                                                  \n",
            " model_3 (Functional)           (None, None, 57892)  34963236    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder_1[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 52,944,164\n",
            "Trainable params: 52,944,164\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/25\n",
            "385/385 [==============================] - 195s 487ms/step - loss: 6.7725 - accuracy: 0.2057 - val_loss: 6.1607 - val_accuracy: 0.2350\n",
            "Epoch 2/25\n",
            "385/385 [==============================] - 168s 436ms/step - loss: 6.0309 - accuracy: 0.2414 - val_loss: 5.3784 - val_accuracy: 0.2815\n",
            "Epoch 3/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 5.2971 - accuracy: 0.2779 - val_loss: 4.6114 - val_accuracy: 0.3285\n",
            "Epoch 4/25\n",
            "385/385 [==============================] - 168s 436ms/step - loss: 4.5653 - accuracy: 0.3199 - val_loss: 3.8280 - val_accuracy: 0.3865\n",
            "Epoch 5/25\n",
            "385/385 [==============================] - 187s 487ms/step - loss: 3.8976 - accuracy: 0.3659 - val_loss: 3.2343 - val_accuracy: 0.4355\n",
            "Epoch 6/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 3.2987 - accuracy: 0.4190 - val_loss: 2.7095 - val_accuracy: 0.5038\n",
            "Epoch 7/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 2.7752 - accuracy: 0.4805 - val_loss: 2.2722 - val_accuracy: 0.5641\n",
            "Epoch 8/25\n",
            "385/385 [==============================] - 187s 487ms/step - loss: 2.3259 - accuracy: 0.5467 - val_loss: 1.9030 - val_accuracy: 0.6223\n",
            "Epoch 9/25\n",
            "385/385 [==============================] - 168s 438ms/step - loss: 1.9122 - accuracy: 0.6155 - val_loss: 1.7223 - val_accuracy: 0.6340\n",
            "Epoch 10/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 1.5633 - accuracy: 0.6778 - val_loss: 1.4108 - val_accuracy: 0.6936\n",
            "Epoch 11/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 1.2316 - accuracy: 0.7412 - val_loss: 1.1940 - val_accuracy: 0.7520\n",
            "Epoch 12/25\n",
            "385/385 [==============================] - 187s 487ms/step - loss: 0.9842 - accuracy: 0.7919 - val_loss: 0.9541 - val_accuracy: 0.7849\n",
            "Epoch 13/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 0.7577 - accuracy: 0.8389 - val_loss: 0.8778 - val_accuracy: 0.8089\n",
            "Epoch 14/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 0.6071 - accuracy: 0.8691 - val_loss: 0.6892 - val_accuracy: 0.8482\n",
            "Epoch 15/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 0.4955 - accuracy: 0.8910 - val_loss: 0.5977 - val_accuracy: 0.8674\n",
            "Epoch 16/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 0.4282 - accuracy: 0.9039 - val_loss: 0.5906 - val_accuracy: 0.8711\n",
            "Epoch 17/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 0.3852 - accuracy: 0.9135 - val_loss: 0.5049 - val_accuracy: 0.8840\n",
            "Epoch 18/25\n",
            "385/385 [==============================] - 168s 436ms/step - loss: 0.3389 - accuracy: 0.9221 - val_loss: 0.4686 - val_accuracy: 0.8949\n",
            "Epoch 19/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 0.3098 - accuracy: 0.9287 - val_loss: 0.4507 - val_accuracy: 0.8982\n",
            "Epoch 20/25\n",
            "385/385 [==============================] - 168s 436ms/step - loss: 0.2775 - accuracy: 0.9357 - val_loss: 0.4039 - val_accuracy: 0.9080\n",
            "Epoch 21/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 0.2563 - accuracy: 0.9404 - val_loss: 0.4005 - val_accuracy: 0.9114\n",
            "Epoch 22/25\n",
            "385/385 [==============================] - 168s 436ms/step - loss: 0.2307 - accuracy: 0.9465 - val_loss: 0.3876 - val_accuracy: 0.9133\n",
            "Epoch 23/25\n",
            "385/385 [==============================] - 168s 438ms/step - loss: 0.2224 - accuracy: 0.9483 - val_loss: 0.3490 - val_accuracy: 0.9219\n",
            "Epoch 24/25\n",
            "385/385 [==============================] - 168s 437ms/step - loss: 0.2071 - accuracy: 0.9515 - val_loss: 0.3553 - val_accuracy: 0.9193\n",
            "Epoch 25/25\n",
            "385/385 [==============================] - 187s 487ms/step - loss: 0.1946 - accuracy: 0.9539 - val_loss: 0.3390 - val_accuracy: 0.9231\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b8671e4a0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save(\"model_trans.h5\")"
      ],
      "metadata": {
        "id": "CnHD5oqg1J6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vocab"
      ],
      "metadata": {
        "id": "geY4j5dJ1fIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Au6uwNZB2Xuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ara_vo = ara_vector.get_vocabulary()\n",
        "ara_index_lookup = dict(zip(range(len(ara_vo)), ara_vo))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vector([input_sentence])\n",
        "    decoded_sentence = \"<start> \"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = ara_vector([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = ara_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \" <end>\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_data]\n"
      ],
      "metadata": {
        "id": "SamU_P-r062E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)"
      ],
      "metadata": {
        "id": "TzF3W_9m3Nz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_sentence)\n",
        "\n",
        "print(translated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93_aVt8x23Kr",
        "outputId": "574ad972-868e-4b3d-95e8-4b0dbc004079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in ecuador ivan petroff shares some of his work done for his studies in artistic expression pointing us to some characteristic features of the colonial plastic arts .\n",
            "<start>  في الاكوادور يشارك ايفان [UNK] بعض من اعماله التي عملها لدراسة الفنون التعبيرية [UNK] انتباهنا لبعض السمات المميزة للفنون [UNK]\n"
          ]
        }
      ]
    }
  ]
}